# -*- coding: utf-8 -*-
"""Rossman.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/********
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
import xgboost as xgb
import operator
import matplotlib
import matplotlib.pyplot as plt



# https://github.com/dmlc/xgboost
# This specific version is a work-around for a build issue in newer versions.
!pip install -q xgboost==0.4a30
import xgboost

from google.colab import files
uploaded = files.upload()

for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))

def build_features(features, data):
    # remove NaNs
    data.fillna(0, inplace=True)
    data.loc[data.Open.isnull(), 'Open'] = 1
    # Use some properties directly
    features.extend(['Store', 'CompetitionDistance', 'Promo', 'Promo2', 'SchoolHoliday'])

    # Label encode some features
    features.extend(['StoreType', 'Assortment', 'StateHoliday'])
    mappings = {'0':0, 'a':1, 'b':2, 'c':3, 'd':4}
    data.StoreType.replace(mappings, inplace=True)
    data.Assortment.replace(mappings, inplace=True)
    data.StateHoliday.replace(mappings, inplace=True)

    features.extend(['DayOfWeek', 'Month', 'Day', 'Year', 'WeekOfYear'])
    data['Year'] = data.Date.dt.year
    data['Month'] = data.Date.dt.month
    data['Day'] = data.Date.dt.day
    data['DayOfWeek'] = data.Date.dt.dayofweek
    data['WeekOfYear'] = data.Date.dt.weekofyear

    # CompetionOpen en PromoOpen from https://www.kaggle.com/ananya77041/rossmann-store-sales/randomforestpython/code
    # Calculate time competition open time in months
    features.append('CompetitionOpen')
    data['CompetitionOpen'] = 12 * (data.Year - data.CompetitionOpenSinceYear) + \
        (data.Month - data.CompetitionOpenSinceMonth)
    # Promo open time in months
    features.append('PromoOpen')
    data['PromoOpen'] = 12 * (data.Year - data.Promo2SinceYear) + \
        (data.WeekOfYear - data.Promo2SinceWeek) / 4.0
    data['PromoOpen'] = data.PromoOpen.apply(lambda x: x if x > 0 else 0)
    data.loc[data.Promo2SinceYear == 0, 'PromoOpen'] = 0

    # Indicate that sales on that day are in promo interval
    features.append('IsPromoMonth')
    month2str = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', \
             7:'Jul', 8:'Aug', 9:'Sept', 10:'Oct', 11:'Nov', 12:'Dec'}
    data['monthStr'] = data.Month.map(month2str)
    data.loc[data.PromoInterval == 0, 'PromoInterval'] = ''
    data['IsPromoMonth'] = 0
    for interval in data.PromoInterval.unique():
        if interval != '':
            for month in interval.split(','):
                data.loc[(data.monthStr == month) & (data.PromoInterval == interval), 'IsPromoMonth'] = 1

    return data

import pandas as pd
import io

types = {'CompetitionOpenSinceYear': np.dtype(int),
         'CompetitionOpenSinceMonth': np.dtype(int),
         'StateHoliday': np.dtype(str),
         'Promo2SinceWeek': np.dtype(int),
         'SchoolHoliday': np.dtype(float),
         'PromoInterval': np.dtype(str)}

train = pd.read_csv(io.StringIO(uploaded['train.csv'].decode('utf-8')), parse_dates=[2])

test = pd.read_csv(io.StringIO(uploaded['test.csv'].decode('utf-8')), parse_dates=[3])

store = pd.read_csv(io.StringIO(uploaded['store.csv'].decode('utf-8')))

print("Assume store open, if not provided")
train.fillna(1, inplace=True)
test.fillna(1, inplace=True)

print("Consider only open stores for training. Closed stores wont count into the score.")
train = train[train["Open"] != 0]
print("Use only Sales bigger then zero. Simplifies calculation of rmspe")
train = train[train["Sales"] > 0]

print("Join with store")
train = pd.merge(train, store, on='Store')
test = pd.merge(test, store, on='Store')

features = []

print("augment features")
build_features(features, train)
build_features([], test)
print(features)
print('training data processed')

# Removing the stores that are not present in test file- Only 
# testing for 856 stores out of 1115
unique = test.Store.unique()
train = train[train['Store'].isin(unique)]

# Split train-validation set
X_train, X_valid = train_test_split(train, test_size=0.012, random_state=10)
y_train = np.log1p(X_train.Sales)
y_valid = np.log1p(X_valid.Sales)

def rmspe(y, yhat):
    return np.sqrt(np.mean(((y-yhat)/y) ** 2))

params = {"objective": "reg:linear",
          "booster" : "gbtree",
          "eta": 0.15,
          "max_depth": 10,
          "subsample": 0.94,
          "colsample_bytree": 0.6,
          "silent": 1,
          "seed": 1301
          }
num_boost_round = 300 #number of iterations

# Used in xgb.train for evaluation
def rmspe_xg(yhat, y):
    y = np.expm1(y.get_label()) #get_label() - Get the label of the DMatrix.
    yhat = np.expm1(yhat)
    return "rmspe", rmspe(y,yhat)


'''
Both xgboost and GBM follows the principle of gradient boosting. There are however,
 the difference in modeling details. Specifically, xgboost used a more regularized 
 model formalization to control over-fitting, which gives it better performance.
 '''

# As required by xgb.train
dtrain = xgb.DMatrix(X_train[features], y_train)
dvalid = xgb.DMatrix(X_valid[features], y_valid)

watchlist = [(dtrain, 'train'), (dvalid, 'eval')]

gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, \
  early_stopping_rounds=100, feval=rmspe_xg, verbose_eval=True)

print("Validating")
yhat = gbm.predict(xgb.DMatrix(X_valid[features]))
error = rmspe(X_valid.Sales.values, np.expm1(yhat))
print('RMSPE: {:.6f}'.format(error))
#RMSPE - Root Mean Square Percentage Error 

test['StateHoliday'] = test['StateHoliday'].astype('int32')
print("Make predictions on the test set")
dtest = xgb.DMatrix(test[features])
test_probs = gbm.predict(dtest)

final_pred = np.expm1(test_probs)

result = pd.DataFrame({"Id": test["Id"], 'Sales': np.expm1(test_probs)})
result = result.sort_values(['Id'], ascending=[True])
print(result.head())

ds = result["Sales"]
with open("out.csv", "w") as subfile:  
    subfile.write("Id,Sales\n")
    for i, pred in enumerate(list(ds)):
        subfile.write("%s,%s\n"%(result.iloc[i,0],result.iloc[i,1]))

files.download('out.csv')